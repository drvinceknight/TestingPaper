\section{Testing the Tests}
How do we know our tests are ``good enough'', and how would we recognise ``good enough''. These are hard questions even in the word of traditional commercial software, where there is (or at least should be) a rigorous specification against which the program can be measured. \cite{Zhuetal1997}.
\begin{description}
\item[Statement coverage]measures the percentage (ideally 100\%) of statements in the programme being tested that have been exercised by the test, or set of tests, in question.
\item[Branch coverage]measures the percentage (ideally 100\%) of possible branches  in the programme being tested that have been exercised by the test, or set of tests, in question.
\end{description}


Vince wrote:

For property based testing
•	https://github.com/baharev
•	https://github.com/debsankha/flownetpy

See also https://www.invincealabs.com/blog/2016/08/fuzzing-nginx-with-afl/
